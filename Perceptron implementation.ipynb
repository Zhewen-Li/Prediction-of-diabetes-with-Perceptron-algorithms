{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from libsvm.commonutil import svm_read_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>-0.531170</td>\n",
       "      <td>-0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.145729</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.766866</td>\n",
       "      <td>-0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.305514</td>\n",
       "      <td>-0.492741</td>\n",
       "      <td>-0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.162444</td>\n",
       "      <td>-0.923997</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>-0.344262</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.602837</td>\n",
       "      <td>0.284650</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>-0.030303</td>\n",
       "      <td>-0.574468</td>\n",
       "      <td>-0.019374</td>\n",
       "      <td>-0.920581</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.764706</td>\n",
       "      <td>0.226131</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.096870</td>\n",
       "      <td>-0.776260</td>\n",
       "      <td>-0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>-0.411765</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.735225</td>\n",
       "      <td>-0.219076</td>\n",
       "      <td>-0.857387</td>\n",
       "      <td>-0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>0.266332</td>\n",
       "      <td>-0.016393</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.102832</td>\n",
       "      <td>-0.768574</td>\n",
       "      <td>-0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.065327</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.373737</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.093890</td>\n",
       "      <td>-0.797609</td>\n",
       "      <td>-0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         4         5         6         7  \\\n",
       "0   -0.294118  0.487437  0.180328 -0.292929 -1.000000  0.001490 -0.531170   \n",
       "1   -0.882353 -0.145729  0.081967 -0.414141 -1.000000 -0.207153 -0.766866   \n",
       "2   -0.058824  0.839196  0.049180 -1.000000 -1.000000 -0.305514 -0.492741   \n",
       "3   -0.882353 -0.105528  0.081967 -0.535354 -0.777778 -0.162444 -0.923997   \n",
       "4   -1.000000  0.376884 -0.344262 -0.292929 -0.602837  0.284650  0.887276   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763  0.176471  0.015075  0.245902 -0.030303 -0.574468 -0.019374 -0.920581   \n",
       "764 -0.764706  0.226131  0.147541 -0.454545 -1.000000  0.096870 -0.776260   \n",
       "765 -0.411765  0.216080  0.180328 -0.535354 -0.735225 -0.219076 -0.857387   \n",
       "766 -0.882353  0.266332 -0.016393 -1.000000 -1.000000 -0.102832 -0.768574   \n",
       "767 -0.882353 -0.065327  0.147541 -0.373737 -1.000000 -0.093890 -0.797609   \n",
       "\n",
       "            8  \n",
       "0   -0.033333  \n",
       "1   -0.666667  \n",
       "2   -0.633333  \n",
       "3   -1.000000  \n",
       "4   -0.600000  \n",
       "..        ...  \n",
       "763  0.400000  \n",
       "764 -0.800000  \n",
       "765 -0.700000  \n",
       "766 -0.133333  \n",
       "767 -0.933333  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "x,y = svm_read_problem('diabetes_scale.txt')\n",
    "diabetes = pd.DataFrame.from_dict(y)\n",
    "\n",
    "# fill missing values with mean column values\n",
    "diabetes = diabetes.fillna(method = 'ffill')\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the dataset into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(diabetes, x, test_size=0.2, random_state=42)\n",
    "\n",
    "# check if there is any nan value in the dataset\n",
    "np.isnan(x_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron implementation from scratch \n",
    "\n",
    "class Perceptron:\n",
    "    #constructor\n",
    "    def __init__ (self, learning_rate=0.1, max_iter=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.activation = self.step_func\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    # activation function: unit step\n",
    "    def step_func(self, x):\n",
    "        return np.where(x>=0, 1, -1)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.bias = 0 \n",
    "        \n",
    "        y_new = np.array([1 if i>0 else -1 for i in y])\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            for j, x_i in enumerate(X):\n",
    "                output = np.dot(x_i, self.weights) + self.bias\n",
    "                y_pred = self.activation(output)\n",
    "                \n",
    "                update = self.learning_rate * (y_new[j] - y_pred)\n",
    "                self.weights += update * x_i\n",
    "                self.bias += update\n",
    "    \n",
    "    def predict(self, x):\n",
    "        output = np.dot(x, self.weights) + self.bias\n",
    "        y_pred = self.activation(output)\n",
    "        return y_pred\n",
    "\n",
    "    def accuracy_score(self, y_pred, y_true):\n",
    "        sum_y = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == y_true[i]:\n",
    "                sum_y += 1\n",
    "        return sum_y/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement cross validation\n",
    "def cross_validation(X, y, k, model):\n",
    "\tn = len(X)\n",
    "\tfold_size = n // k\n",
    "\taccuracy = []\n",
    "\tfor i in range(k):\n",
    "\t\tx_test = X[i*fold_size:(i+1)*fold_size]\n",
    "\t\ty_test = y[i*fold_size:(i+1)*fold_size]\n",
    "\t\tx_train = np.concatenate((X[:i*fold_size], X[(i+1)*fold_size:]), axis=0)\n",
    "\t\ty_train = np.concatenate((y[:i*fold_size], y[(i+1)*fold_size:]), axis=0)\n",
    "\n",
    "\t\t# fit model\n",
    "\t\tmodel.fit(x_train, y_train)\n",
    "\t\ty_pred = model.predict(x_test)\n",
    "\t\taccuracy.append(model.accuracy_score(y_pred, y_test))\n",
    "\treturn accuracy, np.mean(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 accuracy =  [0.6530944625407166] mean accuracy =  0.6530944625407166\n",
      "K =  2 accuracy =  [0.7068403908794788, 0.762214983713355] mean accuracy =  0.7345276872964169\n",
      "K =  3 accuracy =  [0.7794117647058824, 0.7696078431372549, 0.7450980392156863] mean accuracy =  0.7647058823529411\n",
      "K =  4 accuracy =  [0.7712418300653595, 0.7189542483660131, 0.7777777777777778, 0.7450980392156863] mean accuracy =  0.7532679738562091\n",
      "K =  5 accuracy =  [0.6311475409836066, 0.7377049180327869, 0.7540983606557377, 0.7377049180327869, 0.7213114754098361] mean accuracy =  0.7163934426229509\n",
      "K =  6 accuracy =  [0.7058823529411765, 0.4803921568627451, 0.6568627450980392, 0.8431372549019608, 0.6862745098039216, 0.4803921568627451] mean accuracy =  0.6421568627450981\n",
      "K =  7 accuracy =  [0.6551724137931034, 0.8390804597701149, 0.6896551724137931, 0.7701149425287356, 0.3793103448275862, 0.7471264367816092, 0.735632183908046] mean accuracy =  0.6880131362889983\n",
      "K =  8 accuracy =  [0.6710526315789473, 0.6973684210526315, 0.7894736842105263, 0.6842105263157895, 0.7763157894736842, 0.6578947368421053, 0.7105263157894737, 0.5263157894736842] mean accuracy =  0.6891447368421053\n",
      "K =  9 accuracy =  [0.6176470588235294, 0.7205882352941176, 0.6617647058823529, 0.6911764705882353, 0.7794117647058824, 0.8529411764705882, 0.7058823529411765, 0.7352941176470589, 0.7058823529411765] mean accuracy =  0.7189542483660132\n"
     ]
    }
   ],
   "source": [
    "# model initialisation\n",
    "perceptron = Perceptron(learning_rate=0.01, max_iter=1000)\n",
    "\n",
    "# apply k-fold cross-validation, select best K\n",
    "for i in range(1, 10):\n",
    "    accuracy, mean_accuracy = cross_validation(x_train, y_train, i, perceptron)\n",
    "    print(\"K = \", i, \"accuracy = \", accuracy, \"mean accuracy = \", mean_accuracy)\n",
    "\n",
    "#accuracy1 = cross_validation(x_train, y_train, 5, perceptron)\n",
    "#print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7337662337662337"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the result with sklearn Perceptron model\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = Perceptron(max_iter=1000)\n",
    "model.fit(np.array(x_train), np.array(y_train))\n",
    "y_pred = model.predict(np.array(x_test))\n",
    "\n",
    "test_score = accuracy_score(y_pred, y_test)\n",
    "test_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('ptenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "599d821d43c25c54888bdf4a388bfac6ea4b7f2c633e44bcf773355589b51cbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
